{"noir_version":"1.0.0-beta.14+60ccd48e18ad8ce50d5ecda9baf813b712145051","hash":"8969432649816327522","abi":{"parameters":[{"name":"current_balance","type":{"kind":"field"},"visibility":"private"},{"name":"operation_amount","type":{"kind":"field"},"visibility":"private"},{"name":"r_old_balance","type":{"kind":"field"},"visibility":"private"},{"name":"r_new_balance","type":{"kind":"field"},"visibility":"private"},{"name":"sender_pubkey","type":{"kind":"struct","path":"std::embedded_curve_ops::EmbeddedCurvePoint","fields":[{"name":"x","type":{"kind":"field"}},{"name":"y","type":{"kind":"field"}},{"name":"is_infinite","type":{"kind":"boolean"}}]},"visibility":"public"},{"name":"old_balance_x1","type":{"kind":"struct","path":"std::embedded_curve_ops::EmbeddedCurvePoint","fields":[{"name":"x","type":{"kind":"field"}},{"name":"y","type":{"kind":"field"}},{"name":"is_infinite","type":{"kind":"boolean"}}]},"visibility":"public"},{"name":"old_balance_x2","type":{"kind":"struct","path":"std::embedded_curve_ops::EmbeddedCurvePoint","fields":[{"name":"x","type":{"kind":"field"}},{"name":"y","type":{"kind":"field"}},{"name":"is_infinite","type":{"kind":"boolean"}}]},"visibility":"public"},{"name":"from","type":{"kind":"field"},"visibility":"public"},{"name":"to","type":{"kind":"field"},"visibility":"public"},{"name":"token","type":{"kind":"field"},"visibility":"public"},{"name":"chainId","type":{"kind":"field"},"visibility":"public"},{"name":"methodTag","type":{"kind":"field"},"visibility":"public"}],"return_type":{"abi_type":{"kind":"tuple","fields":[{"kind":"tuple","fields":[{"kind":"struct","path":"std::embedded_curve_ops::EmbeddedCurvePoint","fields":[{"name":"x","type":{"kind":"field"}},{"name":"y","type":{"kind":"field"}},{"name":"is_infinite","type":{"kind":"boolean"}}]},{"kind":"struct","path":"std::embedded_curve_ops::EmbeddedCurvePoint","fields":[{"name":"x","type":{"kind":"field"}},{"name":"y","type":{"kind":"field"}},{"name":"is_infinite","type":{"kind":"boolean"}}]}]},{"kind":"field"}]},"visibility":"public"},"error_types":{"12469291177396340830":{"error_kind":"string","string":"call to assert_max_bit_size"},"15764276373176857197":{"error_kind":"string","string":"Stack too deep"}}},"bytecode":"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","debug_symbols":"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","file_map":{"5":{"source":"use crate::meta::derive_via;\n\n#[derive_via(derive_eq)]\n// docs:start:eq-trait\npub trait Eq {\n    fn eq(self, other: Self) -> bool;\n}\n// docs:end:eq-trait\n\n// docs:start:derive_eq\ncomptime fn derive_eq(s: TypeDefinition) -> Quoted {\n    let signature = quote { fn eq(_self: Self, _other: Self) -> bool };\n    let for_each_field = |name| quote { (_self.$name == _other.$name) };\n    let body = |fields| {\n        if s.fields_as_written().len() == 0 {\n            quote { true }\n        } else {\n            fields\n        }\n    };\n    crate::meta::make_trait_impl(\n        s,\n        quote { $crate::cmp::Eq },\n        signature,\n        for_each_field,\n        quote { & },\n        body,\n    )\n}\n// docs:end:derive_eq\n\nimpl Eq for Field {\n    fn eq(self, other: Field) -> bool {\n        self == other\n    }\n}\n\nimpl Eq for u128 {\n    fn eq(self, other: u128) -> bool {\n        self == other\n    }\n}\nimpl Eq for u64 {\n    fn eq(self, other: u64) -> bool {\n        self == other\n    }\n}\nimpl Eq for u32 {\n    fn eq(self, other: u32) -> bool {\n        self == other\n    }\n}\nimpl Eq for u16 {\n    fn eq(self, other: u16) -> bool {\n        self == other\n    }\n}\nimpl Eq for u8 {\n    fn eq(self, other: u8) -> bool {\n        self == other\n    }\n}\nimpl Eq for u1 {\n    fn eq(self, other: u1) -> bool {\n        self == other\n    }\n}\n\nimpl Eq for i8 {\n    fn eq(self, other: i8) -> bool {\n        self == other\n    }\n}\nimpl Eq for i16 {\n    fn eq(self, other: i16) -> bool {\n        self == other\n    }\n}\nimpl Eq for i32 {\n    fn eq(self, other: i32) -> bool {\n        self == other\n    }\n}\nimpl Eq for i64 {\n    fn eq(self, other: i64) -> bool {\n        self == other\n    }\n}\n\nimpl Eq for () {\n    fn eq(_self: Self, _other: ()) -> bool {\n        true\n    }\n}\nimpl Eq for bool {\n    fn eq(self, other: bool) -> bool {\n        self == other\n    }\n}\n\nimpl<T, let N: u32> Eq for [T; N]\nwhere\n    T: Eq,\n{\n    fn eq(self, other: [T; N]) -> bool {\n        let mut result = true;\n        for i in 0..self.len() {\n            result &= self[i].eq(other[i]);\n        }\n        result\n    }\n}\n\nimpl<T> Eq for [T]\nwhere\n    T: Eq,\n{\n    fn eq(self, other: [T]) -> bool {\n        let mut result = self.len() == other.len();\n        if result {\n            for i in 0..self.len() {\n                result &= self[i].eq(other[i]);\n            }\n        }\n        result\n    }\n}\n\nimpl<let N: u32> Eq for str<N> {\n    fn eq(self, other: str<N>) -> bool {\n        let self_bytes = self.as_bytes();\n        let other_bytes = other.as_bytes();\n        self_bytes == other_bytes\n    }\n}\n\nimpl<A, B> Eq for (A, B)\nwhere\n    A: Eq,\n    B: Eq,\n{\n    fn eq(self, other: (A, B)) -> bool {\n        self.0.eq(other.0) & self.1.eq(other.1)\n    }\n}\n\nimpl<A, B, C> Eq for (A, B, C)\nwhere\n    A: Eq,\n    B: Eq,\n    C: Eq,\n{\n    fn eq(self, other: (A, B, C)) -> bool {\n        self.0.eq(other.0) & self.1.eq(other.1) & self.2.eq(other.2)\n    }\n}\n\nimpl<A, B, C, D> Eq for (A, B, C, D)\nwhere\n    A: Eq,\n    B: Eq,\n    C: Eq,\n    D: Eq,\n{\n    fn eq(self, other: (A, B, C, D)) -> bool {\n        self.0.eq(other.0) & self.1.eq(other.1) & self.2.eq(other.2) & self.3.eq(other.3)\n    }\n}\n\nimpl<A, B, C, D, E> Eq for (A, B, C, D, E)\nwhere\n    A: Eq,\n    B: Eq,\n    C: Eq,\n    D: Eq,\n    E: Eq,\n{\n    fn eq(self, other: (A, B, C, D, E)) -> bool {\n        self.0.eq(other.0)\n            & self.1.eq(other.1)\n            & self.2.eq(other.2)\n            & self.3.eq(other.3)\n            & self.4.eq(other.4)\n    }\n}\n\nimpl Eq for Ordering {\n    fn eq(self, other: Ordering) -> bool {\n        self.result == other.result\n    }\n}\n\n// Noir doesn't have enums yet so we emulate (Lt | Eq | Gt) with a struct\n// that has 3 public functions for constructing the struct.\npub struct Ordering {\n    result: Field,\n}\n\nimpl Ordering {\n    // Implementation note: 0, 1, and 2 for Lt, Eq, and Gt are built\n    // into the compiler, do not change these without also updating\n    // the compiler itself!\n    pub fn less() -> Ordering {\n        Ordering { result: 0 }\n    }\n\n    pub fn equal() -> Ordering {\n        Ordering { result: 1 }\n    }\n\n    pub fn greater() -> Ordering {\n        Ordering { result: 2 }\n    }\n}\n\n#[derive_via(derive_ord)]\n// docs:start:ord-trait\npub trait Ord {\n    fn cmp(self, other: Self) -> Ordering;\n}\n// docs:end:ord-trait\n\n// docs:start:derive_ord\ncomptime fn derive_ord(s: TypeDefinition) -> Quoted {\n    let name = quote { $crate::cmp::Ord };\n    let signature = quote { fn cmp(_self: Self, _other: Self) -> $crate::cmp::Ordering };\n    let for_each_field = |name| quote {\n        if result == $crate::cmp::Ordering::equal() {\n            result = _self.$name.cmp(_other.$name);\n        }\n    };\n    let body = |fields| quote {\n        let mut result = $crate::cmp::Ordering::equal();\n        $fields\n        result\n    };\n    crate::meta::make_trait_impl(s, name, signature, for_each_field, quote {}, body)\n}\n// docs:end:derive_ord\n\n// Note: Field deliberately does not implement Ord\n\nimpl Ord for u128 {\n    fn cmp(self, other: u128) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\nimpl Ord for u64 {\n    fn cmp(self, other: u64) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl Ord for u32 {\n    fn cmp(self, other: u32) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl Ord for u16 {\n    fn cmp(self, other: u16) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl Ord for u8 {\n    fn cmp(self, other: u8) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl Ord for i8 {\n    fn cmp(self, other: i8) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl Ord for i16 {\n    fn cmp(self, other: i16) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl Ord for i32 {\n    fn cmp(self, other: i32) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl Ord for i64 {\n    fn cmp(self, other: i64) -> Ordering {\n        if self < other {\n            Ordering::less()\n        } else if self > other {\n            Ordering::greater()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl Ord for () {\n    fn cmp(_self: Self, _other: ()) -> Ordering {\n        Ordering::equal()\n    }\n}\n\nimpl Ord for bool {\n    fn cmp(self, other: bool) -> Ordering {\n        if self {\n            if other {\n                Ordering::equal()\n            } else {\n                Ordering::greater()\n            }\n        } else if other {\n            Ordering::less()\n        } else {\n            Ordering::equal()\n        }\n    }\n}\n\nimpl<T, let N: u32> Ord for [T; N]\nwhere\n    T: Ord,\n{\n    // The first non-equal element of both arrays determines\n    // the ordering for the whole array.\n    fn cmp(self, other: [T; N]) -> Ordering {\n        let mut result = Ordering::equal();\n        for i in 0..self.len() {\n            if result == Ordering::equal() {\n                result = self[i].cmp(other[i]);\n            }\n        }\n        result\n    }\n}\n\nimpl<T> Ord for [T]\nwhere\n    T: Ord,\n{\n    // The first non-equal element of both arrays determines\n    // the ordering for the whole array.\n    fn cmp(self, other: [T]) -> Ordering {\n        let self_len = self.len();\n        let other_len = other.len();\n        let min_len = if self_len < other_len {\n            self_len\n        } else {\n            other_len\n        };\n\n        let mut result = Ordering::equal();\n        for i in 0..min_len {\n            if result == Ordering::equal() {\n                result = self[i].cmp(other[i]);\n            }\n        }\n\n        if result != Ordering::equal() {\n            result\n        } else {\n            self_len.cmp(other_len)\n        }\n    }\n}\n\nimpl<A, B> Ord for (A, B)\nwhere\n    A: Ord,\n    B: Ord,\n{\n    fn cmp(self, other: (A, B)) -> Ordering {\n        let result = self.0.cmp(other.0);\n\n        if result != Ordering::equal() {\n            result\n        } else {\n            self.1.cmp(other.1)\n        }\n    }\n}\n\nimpl<A, B, C> Ord for (A, B, C)\nwhere\n    A: Ord,\n    B: Ord,\n    C: Ord,\n{\n    fn cmp(self, other: (A, B, C)) -> Ordering {\n        let mut result = self.0.cmp(other.0);\n\n        if result == Ordering::equal() {\n            result = self.1.cmp(other.1);\n        }\n\n        if result == Ordering::equal() {\n            result = self.2.cmp(other.2);\n        }\n\n        result\n    }\n}\n\nimpl<A, B, C, D> Ord for (A, B, C, D)\nwhere\n    A: Ord,\n    B: Ord,\n    C: Ord,\n    D: Ord,\n{\n    fn cmp(self, other: (A, B, C, D)) -> Ordering {\n        let mut result = self.0.cmp(other.0);\n\n        if result == Ordering::equal() {\n            result = self.1.cmp(other.1);\n        }\n\n        if result == Ordering::equal() {\n            result = self.2.cmp(other.2);\n        }\n\n        if result == Ordering::equal() {\n            result = self.3.cmp(other.3);\n        }\n\n        result\n    }\n}\n\nimpl<A, B, C, D, E> Ord for (A, B, C, D, E)\nwhere\n    A: Ord,\n    B: Ord,\n    C: Ord,\n    D: Ord,\n    E: Ord,\n{\n    fn cmp(self, other: (A, B, C, D, E)) -> Ordering {\n        let mut result = self.0.cmp(other.0);\n\n        if result == Ordering::equal() {\n            result = self.1.cmp(other.1);\n        }\n\n        if result == Ordering::equal() {\n            result = self.2.cmp(other.2);\n        }\n\n        if result == Ordering::equal() {\n            result = self.3.cmp(other.3);\n        }\n\n        if result == Ordering::equal() {\n            result = self.4.cmp(other.4);\n        }\n\n        result\n    }\n}\n\n// Compares and returns the maximum of two values.\n//\n// Returns the second argument if the comparison determines them to be equal.\n//\n// # Examples\n//\n// ```\n// use std::cmp;\n//\n// assert_eq(cmp::max(1, 2), 2);\n// assert_eq(cmp::max(2, 2), 2);\n// ```\npub fn max<T>(v1: T, v2: T) -> T\nwhere\n    T: Ord,\n{\n    if v1 > v2 {\n        v1\n    } else {\n        v2\n    }\n}\n\n// Compares and returns the minimum of two values.\n//\n// Returns the first argument if the comparison determines them to be equal.\n//\n// # Examples\n//\n// ```\n// use std::cmp;\n//\n// assert_eq(cmp::min(1, 2), 1);\n// assert_eq(cmp::min(2, 2), 2);\n// ```\npub fn min<T>(v1: T, v2: T) -> T\nwhere\n    T: Ord,\n{\n    if v1 > v2 {\n        v2\n    } else {\n        v1\n    }\n}\n\nmod cmp_tests {\n    use super::{Eq, max, min, Ord};\n\n    #[test]\n    fn sanity_check_min() {\n        assert_eq(min(0_u64, 1), 0);\n        assert_eq(min(0_u64, 0), 0);\n        assert_eq(min(1_u64, 1), 1);\n        assert_eq(min(255_u8, 0), 0);\n    }\n\n    #[test]\n    fn sanity_check_max() {\n        assert_eq(max(0_u64, 1), 1);\n        assert_eq(max(0_u64, 0), 0);\n        assert_eq(max(1_u64, 1), 1);\n        assert_eq(max(255_u8, 0), 255);\n    }\n\n    #[test]\n    fn correctly_handles_unequal_length_slices() {\n        let slice_1 = &[0, 1, 2, 3];\n        let slice_2 = &[0, 1, 2];\n        assert(!slice_1.eq(slice_2));\n    }\n\n    #[test]\n    fn lexicographic_ordering_for_slices() {\n        assert(&[2_u32].cmp(&[1_u32, 1_u32, 1_u32]) == super::Ordering::greater());\n        assert(&[1_u32, 2_u32].cmp(&[1_u32, 2_u32, 3_u32]) == super::Ordering::less());\n    }\n}\n","path":"std/cmp.nr"},"16":{"source":"use crate::cmp::Eq;\nuse crate::hash::Hash;\nuse crate::ops::arith::{Add, Neg, Sub};\n\n/// A point on the embedded elliptic curve\n/// By definition, the base field of the embedded curve is the scalar field of the proof system curve, i.e the Noir Field.\n/// x and y denotes the Weierstrass coordinates of the point, if is_infinite is false.\npub struct EmbeddedCurvePoint {\n    pub x: Field,\n    pub y: Field,\n    pub is_infinite: bool,\n}\n\nimpl EmbeddedCurvePoint {\n    /// Elliptic curve point doubling operation\n    /// returns the doubled point of a point P, i.e P+P\n    pub fn double(self) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, self)\n    }\n\n    /// Returns the null element of the curve; 'the point at infinity'\n    pub fn point_at_infinity() -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: 0, y: 0, is_infinite: true }\n    }\n\n    /// Returns the curve's generator point.\n    pub fn generator() -> EmbeddedCurvePoint {\n        // Generator point for the grumpkin curve (y^2 = x^3 - 17)\n        EmbeddedCurvePoint {\n            x: 1,\n            y: 17631683881184975370165255887551781615748388533673675138860, // sqrt(-16)\n            is_infinite: false,\n        }\n    }\n}\n\nimpl Add for EmbeddedCurvePoint {\n    /// Adds two points P+Q, using the curve addition formula, and also handles point at infinity\n    fn add(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        embedded_curve_add(self, other)\n    }\n}\n\nimpl Sub for EmbeddedCurvePoint {\n    /// Points subtraction operation, using addition and negation\n    fn sub(self, other: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n        self + other.neg()\n    }\n}\n\nimpl Neg for EmbeddedCurvePoint {\n    /// Negates a point P, i.e returns -P, by negating the y coordinate.\n    /// If the point is at infinity, then the result is also at infinity.\n    fn neg(self) -> EmbeddedCurvePoint {\n        EmbeddedCurvePoint { x: self.x, y: -self.y, is_infinite: self.is_infinite }\n    }\n}\n\nimpl Eq for EmbeddedCurvePoint {\n    /// Checks whether two points are equal\n    fn eq(self: Self, b: EmbeddedCurvePoint) -> bool {\n        (self.is_infinite & b.is_infinite)\n            | ((self.is_infinite == b.is_infinite) & (self.x == b.x) & (self.y == b.y))\n    }\n}\n\nimpl Hash for EmbeddedCurvePoint {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        if self.is_infinite {\n            self.is_infinite.hash(state);\n        } else {\n            self.x.hash(state);\n            self.y.hash(state);\n        }\n    }\n}\n\n/// Scalar for the embedded curve represented as low and high limbs\n/// By definition, the scalar field of the embedded curve is base field of the proving system curve.\n/// It may not fit into a Field element, so it is represented with two Field elements; its low and high limbs.\npub struct EmbeddedCurveScalar {\n    pub lo: Field,\n    pub hi: Field,\n}\n\nimpl EmbeddedCurveScalar {\n    pub fn new(lo: Field, hi: Field) -> Self {\n        EmbeddedCurveScalar { lo, hi }\n    }\n\n    #[field(bn254)]\n    pub fn from_field(scalar: Field) -> EmbeddedCurveScalar {\n        let (a, b) = crate::field::bn254::decompose(scalar);\n        EmbeddedCurveScalar { lo: a, hi: b }\n    }\n\n    //Bytes to scalar: take the first (after the specified offset) 16 bytes of the input as the lo value, and the next 16 bytes as the hi value\n    #[field(bn254)]\n    pub(crate) fn from_bytes(bytes: [u8; 64], offset: u32) -> EmbeddedCurveScalar {\n        let mut v = 1;\n        let mut lo = 0 as Field;\n        let mut hi = 0 as Field;\n        for i in 0..16 {\n            lo = lo + (bytes[offset + 31 - i] as Field) * v;\n            hi = hi + (bytes[offset + 15 - i] as Field) * v;\n            v = v * 256;\n        }\n        let sig_s = crate::embedded_curve_ops::EmbeddedCurveScalar { lo, hi };\n        sig_s\n    }\n}\n\nimpl Eq for EmbeddedCurveScalar {\n    fn eq(self, other: Self) -> bool {\n        (other.hi == self.hi) & (other.lo == self.lo)\n    }\n}\n\nimpl Hash for EmbeddedCurveScalar {\n    fn hash<H>(self, state: &mut H)\n    where\n        H: crate::hash::Hasher,\n    {\n        self.hi.hash(state);\n        self.lo.hash(state);\n    }\n}\n\n// Computes a multi scalar multiplication over the embedded curve.\n// For bn254, We have Grumpkin and Baby JubJub.\n// For bls12-381, we have JubJub and Bandersnatch.\n//\n// The embedded curve being used is decided by the\n// underlying proof system.\n// docs:start:multi_scalar_mul\npub fn multi_scalar_mul<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n) -> EmbeddedCurvePoint\n// docs:end:multi_scalar_mul\n{\n    multi_scalar_mul_array_return(points, scalars, true)[0]\n}\n\n#[foreign(multi_scalar_mul)]\npub(crate) fn multi_scalar_mul_array_return<let N: u32>(\n    points: [EmbeddedCurvePoint; N],\n    scalars: [EmbeddedCurveScalar; N],\n    predicate: bool,\n) -> [EmbeddedCurvePoint; 1] {}\n\n// docs:start:fixed_base_scalar_mul\npub fn fixed_base_scalar_mul(scalar: EmbeddedCurveScalar) -> EmbeddedCurvePoint\n// docs:end:fixed_base_scalar_mul\n{\n    multi_scalar_mul([EmbeddedCurvePoint::generator()], [scalar])\n}\n\n/// This function only assumes that the points are on the curve\n/// It handles corner cases around the infinity point causing some overhead compared to embedded_curve_add_not_nul and embedded_curve_add_unsafe\n// docs:start:embedded_curve_add\npub fn embedded_curve_add(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    // docs:end:embedded_curve_add\n    if crate::runtime::is_unconstrained() {\n        // `embedded_curve_add_unsafe` requires the inputs not to be the infinity point, so we check it here.\n        // This is because `embedded_curve_add_unsafe` uses the `embedded_curve_add` opcode.\n        // For efficiency, the backend does not check the inputs for the infinity point, but it assumes that they are not the infinity point\n        // so that it can apply the ec addition formula directly.\n        if point1.is_infinite {\n            point2\n        } else if point2.is_infinite {\n            point1\n        } else {\n            embedded_curve_add_unsafe(point1, point2)\n        }\n    } else {\n        // In a constrained context, we also need to check the inputs are not the infinity point because we also use `embedded_curve_add_unsafe`\n        // However we also need to identify the case where the two inputs are the same, because then\n        // the addition formula does not work and we need to use the doubling formula instead.\n        // In unconstrained context, we can check directly if the input values are the same when solving the opcode, so it is not an issue.\n\n        // x_coordinates_match is true if both abscissae are the same\n        let x_coordinates_match = point1.x == point2.x;\n        // y_coordinates_match is true if both ordinates are the same\n        let y_coordinates_match = point1.y == point2.y;\n        // double_predicate is true if both abscissae and ordinates are the same\n        let double_predicate = (x_coordinates_match & y_coordinates_match);\n        // If the abscissae are the same, but not the ordinates, then one point is the opposite of the other\n        let infinity_predicate = (x_coordinates_match & !y_coordinates_match);\n\n        // `embedded_curve_add_unsafe` would not perform doubling, even if the inputs point1 and point2 are the same, because it cannot know this without adding some logic (and some constraints)\n        // However we did this logic when we computed `double_predicate`, so we set the result to 2*point1 if point1 and point2 are the same\n        let mut result = if double_predicate {\n            // `embedded_curve_add_unsafe` is doing a doubling if the input is the same variable, because in this case it is guaranteed (at 'compile time') that the input is the same.\n            embedded_curve_add_unsafe(point1, point1)\n        } else {\n            let point1_1 = EmbeddedCurvePoint {\n                x: point1.x + (x_coordinates_match as Field),\n                y: point1.y,\n                is_infinite: false,\n            };\n            let point2_1 = EmbeddedCurvePoint { x: point2.x, y: point2.y, is_infinite: false };\n            // point1_1 is guaranteed to have a different abscissa than point2:\n            // - if x_coordinates_match is 0, that means point1.x != point2.x, and point1_1.x = point1.x + 0\n            // - if x_coordinates_match is 1, that means point1.x = point2.x, but point1_1.x = point1.x + 1 in this case\n            // Because the abscissa is different, the addition formula is guaranteed to succeed, so we can safely use `embedded_curve_add_unsafe`\n            // Note that this computation may be garbage: if x_coordinates_match is 1, or if one of the input is the point at infinity.\n            // therefore we only want to do this if we need the result, otherwise it needs to be eliminated as a dead instruction, lest we want the circuit to fail.\n            embedded_curve_add_unsafe(point1_1, point2_1)\n        };\n\n        // Same logic as above for unconstrained context, we set the proper result when one of the inputs is the infinity point\n        if point1.is_infinite {\n            result = point2;\n        }\n        if point2.is_infinite {\n            result = point1;\n        }\n\n        // Finally, we set the is_infinity flag of the result:\n        // Opposite points should sum into the infinity point, however, if one of them is point at infinity, their coordinates are not meaningful\n        // so we should not use the fact that the inputs are opposite in this case:\n        let mut result_is_infinity =\n            infinity_predicate & (!point1.is_infinite & !point2.is_infinite);\n        // However, if both of them are at infinity, then the result is also at infinity\n        result.is_infinite = result_is_infinity | (point1.is_infinite & point2.is_infinite);\n        result\n    }\n}\n\n#[foreign(embedded_curve_add)]\nfn embedded_curve_add_array_return(\n    _point1: EmbeddedCurvePoint,\n    _point2: EmbeddedCurvePoint,\n    _predicate: bool,\n) -> [EmbeddedCurvePoint; 1] {}\n\n/// This function assumes that:\n/// The points are on the curve, and\n/// The points don't share an x-coordinate, and\n/// Neither point is the infinity point.\n/// If it is used with correct input, the function ensures the correct non-zero result is returned.\n/// Except for points on the curve, the other assumptions are checked by the function. It will cause assertion failure if they are not respected.\npub fn embedded_curve_add_not_nul(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    assert(point1.x != point2.x);\n    assert(!point1.is_infinite);\n    assert(!point2.is_infinite);\n    // Ensure is_infinite is comptime\n    let point1_1 = EmbeddedCurvePoint { x: point1.x, y: point1.y, is_infinite: false };\n    let point2_1 = EmbeddedCurvePoint { x: point2.x, y: point2.y, is_infinite: false };\n    embedded_curve_add_unsafe(point1_1, point2_1)\n}\n\n/// Unsafe ec addition\n/// If the inputs are the same, it will perform a doubling, but only if point1 and point2 are the same variable.\n/// If they have the same value but are different variables, the result will be incorrect because in this case\n/// it assumes (but does not check) that the points' x-coordinates are not equal.\n/// It also assumes neither point is the infinity point.\npub fn embedded_curve_add_unsafe(\n    point1: EmbeddedCurvePoint,\n    point2: EmbeddedCurvePoint,\n) -> EmbeddedCurvePoint {\n    embedded_curve_add_array_return(point1, point2, true)[0]\n}\n","path":"std/embedded_curve_ops.nr"},"17":{"source":"use crate::field::field_less_than;\nuse crate::runtime::is_unconstrained;\n\n// The low and high decomposition of the field modulus\nglobal PLO: Field = 53438638232309528389504892708671455233;\nglobal PHI: Field = 64323764613183177041862057485226039389;\n\npub(crate) global TWO_POW_128: Field = 0x100000000000000000000000000000000;\n\n// Decomposes a single field into two 16 byte fields.\nfn compute_decomposition(x: Field) -> (Field, Field) {\n    // Here's we're taking advantage of truncating 128 bit limbs from the input field\n    // and then subtracting them from the input such the field division is equivalent to integer division.\n    let low = (x as u128) as Field;\n    let high = (x - low) / TWO_POW_128;\n\n    (low, high)\n}\n\npub(crate) unconstrained fn decompose_hint(x: Field) -> (Field, Field) {\n    compute_decomposition(x)\n}\n\nunconstrained fn lte_hint(x: Field, y: Field) -> bool {\n    if x == y {\n        true\n    } else {\n        field_less_than(x, y)\n    }\n}\n\n// Assert that (alo > blo && ahi >= bhi) || (alo <= blo && ahi > bhi)\nfn assert_gt_limbs(a: (Field, Field), b: (Field, Field)) {\n    let (alo, ahi) = a;\n    let (blo, bhi) = b;\n    // Safety: borrow is enforced to be boolean due to its type.\n    // if borrow is 0, it asserts that (alo > blo && ahi >= bhi)\n    // if borrow is 1, it asserts that (alo <= blo && ahi > bhi)\n    unsafe {\n        let borrow = lte_hint(alo, blo);\n\n        let rlo = alo - blo - 1 + (borrow as Field) * TWO_POW_128;\n        let rhi = ahi - bhi - (borrow as Field);\n\n        rlo.assert_max_bit_size::<128>();\n        rhi.assert_max_bit_size::<128>();\n    }\n}\n\n/// Decompose a single field into two 16 byte fields.\npub fn decompose(x: Field) -> (Field, Field) {\n    if is_unconstrained() {\n        compute_decomposition(x)\n    } else {\n        // Safety: decomposition is properly checked below\n        unsafe {\n            // Take hints of the decomposition\n            let (xlo, xhi) = decompose_hint(x);\n\n            // Range check the limbs\n            xlo.assert_max_bit_size::<128>();\n            xhi.assert_max_bit_size::<128>();\n\n            // Check that the decomposition is correct\n            assert_eq(x, xlo + TWO_POW_128 * xhi);\n\n            // Assert that the decomposition of P is greater than the decomposition of x\n            assert_gt_limbs((PLO, PHI), (xlo, xhi));\n            (xlo, xhi)\n        }\n    }\n}\n\npub fn assert_gt(a: Field, b: Field) {\n    if is_unconstrained() {\n        assert(\n            // Safety: already unconstrained\n            unsafe { field_less_than(b, a) },\n        );\n    } else {\n        // Decompose a and b\n        let a_limbs = decompose(a);\n        let b_limbs = decompose(b);\n\n        // Assert that a_limbs is greater than b_limbs\n        assert_gt_limbs(a_limbs, b_limbs)\n    }\n}\n\npub fn assert_lt(a: Field, b: Field) {\n    assert_gt(b, a);\n}\n\npub fn gt(a: Field, b: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unsafe in unconstrained\n        unsafe {\n            field_less_than(b, a)\n        }\n    } else if a == b {\n        false\n    } else {\n        // Safety: Take a hint of the comparison and verify it\n        unsafe {\n            if field_less_than(a, b) {\n                assert_gt(b, a);\n                false\n            } else {\n                assert_gt(a, b);\n                true\n            }\n        }\n    }\n}\n\npub fn lt(a: Field, b: Field) -> bool {\n    gt(b, a)\n}\n\nmod tests {\n    // TODO: Allow imports from \"super\"\n    use crate::field::bn254::{assert_gt, decompose, gt, lt, lte_hint, PHI, PLO, TWO_POW_128};\n\n    #[test]\n    fn check_decompose() {\n        assert_eq(decompose(TWO_POW_128), (0, 1));\n        assert_eq(decompose(TWO_POW_128 + 0x1234567890), (0x1234567890, 1));\n        assert_eq(decompose(0x1234567890), (0x1234567890, 0));\n    }\n\n    #[test]\n    unconstrained fn check_lte_hint() {\n        assert(lte_hint(0, 1));\n        assert(lte_hint(0, 0x100));\n        assert(lte_hint(0x100, TWO_POW_128 - 1));\n        assert(!lte_hint(0 - 1, 0));\n\n        assert(lte_hint(0, 0));\n        assert(lte_hint(0x100, 0x100));\n        assert(lte_hint(0 - 1, 0 - 1));\n    }\n\n    #[test]\n    fn check_gt() {\n        assert(gt(1, 0));\n        assert(gt(0x100, 0));\n        assert(gt((0 - 1), (0 - 2)));\n        assert(gt(TWO_POW_128, 0));\n        assert(!gt(0, 0));\n        assert(!gt(0, 0x100));\n        assert(gt(0 - 1, 0 - 2));\n        assert(!gt(0 - 2, 0 - 1));\n        assert_gt(0 - 1, 0);\n    }\n\n    #[test]\n    fn check_plo_phi() {\n        assert_eq(PLO + PHI * TWO_POW_128, 0);\n        let p_bytes = crate::field::modulus_le_bytes();\n        let mut p_low: Field = 0;\n        let mut p_high: Field = 0;\n\n        let mut offset = 1;\n        for i in 0..16 {\n            p_low += (p_bytes[i] as Field) * offset;\n            p_high += (p_bytes[i + 16] as Field) * offset;\n            offset *= 256;\n        }\n        assert_eq(p_low, PLO);\n        assert_eq(p_high, PHI);\n    }\n\n    #[test]\n    fn check_decompose_edge_cases() {\n        assert_eq(decompose(0), (0, 0));\n        assert_eq(decompose(TWO_POW_128 - 1), (TWO_POW_128 - 1, 0));\n        assert_eq(decompose(TWO_POW_128 + 1), (1, 1));\n        assert_eq(decompose(TWO_POW_128 * 2), (0, 2));\n        assert_eq(decompose(TWO_POW_128 * 2 + 0x1234567890), (0x1234567890, 2));\n    }\n\n    #[test]\n    fn check_decompose_large_values() {\n        let large_field = 0xffffffffffffffff;\n        let (lo, hi) = decompose(large_field);\n        assert_eq(large_field, lo + TWO_POW_128 * hi);\n\n        let large_value = large_field - TWO_POW_128;\n        let (lo2, hi2) = decompose(large_value);\n        assert_eq(large_value, lo2 + TWO_POW_128 * hi2);\n    }\n\n    #[test]\n    fn check_lt_comprehensive() {\n        assert(lt(0, 1));\n        assert(!lt(1, 0));\n        assert(!lt(0, 0));\n        assert(!lt(42, 42));\n\n        assert(lt(TWO_POW_128 - 1, TWO_POW_128));\n        assert(!lt(TWO_POW_128, TWO_POW_128 - 1));\n    }\n}\n","path":"std/field/bn254.nr"},"18":{"source":"pub mod bn254;\nuse crate::{runtime::is_unconstrained, static_assert};\nuse bn254::lt as bn254_lt;\n\nimpl Field {\n    /// Asserts that `self` can be represented in `bit_size` bits.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^{bit_size}`.\n    // docs:start:assert_max_bit_size\n    pub fn assert_max_bit_size<let BIT_SIZE: u32>(self) {\n        // docs:end:assert_max_bit_size\n        static_assert(\n            BIT_SIZE < modulus_num_bits() as u32,\n            \"BIT_SIZE must be less than modulus_num_bits\",\n        );\n        __assert_max_bit_size(self, BIT_SIZE);\n    }\n\n    /// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n    /// This slice will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_le_bits\n    pub fn to_le_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_le_bits\n        let bits = __to_le_bits(self);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[N - 1 - i] != p[N - 1 - i]) {\n                        assert(p[N - 1 - i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n    /// This array will be zero padded should not all bits be necessary to represent `self`.\n    ///\n    /// # Failures\n    /// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n    /// be able to represent the original `Field`.\n    ///\n    /// # Safety\n    /// The bit decomposition returned is canonical and is guaranteed to not overflow the modulus.\n    // docs:start:to_be_bits\n    pub fn to_be_bits<let N: u32>(self: Self) -> [u1; N] {\n        // docs:end:to_be_bits\n        let bits = __to_be_bits(self);\n\n        if !is_unconstrained() {\n            // Ensure that the decomposition does not overflow the modulus\n            let p = modulus_be_bits();\n            assert(bits.len() <= p.len());\n            let mut ok = bits.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bits[i] != p[i]) {\n                        assert(p[i] == 1);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bits\n    }\n\n    /// Decomposes `self` into its little endian byte decomposition as a `[u8;N]` array\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_le_bytes\n    pub fn to_le_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_le_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_le_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_le_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[N - 1 - i] != p[N - 1 - i]) {\n                        assert(bytes[N - 1 - i] < p[N - 1 - i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    /// Decomposes `self` into its big endian byte decomposition as a `[u8;N]` array of length required to represent the field modulus\n    /// This array will be zero padded should not all bytes be necessary to represent `self`.\n    ///\n    /// # Failures\n    ///  The length N of the array must be big enough to contain all the bytes of the 'self',\n    ///  and no more than the number of bytes required to represent the field modulus\n    ///\n    /// # Safety\n    /// The result is ensured to be the canonical decomposition of the field element\n    // docs:start:to_be_bytes\n    pub fn to_be_bytes<let N: u32>(self: Self) -> [u8; N] {\n        // docs:end:to_be_bytes\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        // Compute the byte decomposition\n        let bytes = self.to_be_radix(256);\n\n        if !is_unconstrained() {\n            // Ensure that the byte decomposition does not overflow the modulus\n            let p = modulus_be_bytes();\n            assert(bytes.len() <= p.len());\n            let mut ok = bytes.len() != p.len();\n            for i in 0..N {\n                if !ok {\n                    if (bytes[i] != p[i]) {\n                        assert(bytes[i] < p[i]);\n                        ok = true;\n                    }\n                }\n            }\n            assert(ok);\n        }\n        bytes\n    }\n\n    fn to_le_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        __to_le_radix(self, radix)\n    }\n\n    fn to_be_radix<let N: u32>(self: Self, radix: u32) -> [u8; N] {\n        // Brillig does not need an immediate radix\n        if !crate::runtime::is_unconstrained() {\n            static_assert(1 < radix, \"radix must be greater than 1\");\n            static_assert(radix <= 256, \"radix must be less than or equal to 256\");\n            static_assert(radix & (radix - 1) == 0, \"radix must be a power of 2\");\n        }\n        __to_be_radix(self, radix)\n    }\n\n    // Returns self to the power of the given exponent value.\n    // Caution: we assume the exponent fits into 32 bits\n    // using a bigger bit size impacts negatively the performance and should be done only if the exponent does not fit in 32 bits\n    pub fn pow_32(self, exponent: Field) -> Field {\n        let mut r: Field = 1;\n        let b: [u1; 32] = exponent.to_le_bits();\n\n        for i in 1..33 {\n            r *= r;\n            r = (b[32 - i] as Field) * (r * self) + (1 - b[32 - i] as Field) * r;\n        }\n        r\n    }\n\n    // Parity of (prime) Field element, i.e. sgn0(x mod p) = 0 if x `elem` {0, ..., p-1} is even, otherwise sgn0(x mod p) = 1.\n    pub fn sgn0(self) -> u1 {\n        self as u1\n    }\n\n    pub fn lt(self, another: Field) -> bool {\n        if crate::compat::is_bn254() {\n            bn254_lt(self, another)\n        } else {\n            lt_fallback(self, another)\n        }\n    }\n\n    /// Convert a little endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_le_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        static_assert(\n            N <= modulus_le_bytes().len(),\n            \"N must be less than or equal to modulus_le_bytes().len()\",\n        );\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n\n    /// Convert a big endian byte array to a field element.\n    /// If the provided byte array overflows the field modulus then the Field will silently wrap around.\n    pub fn from_be_bytes<let N: u32>(bytes: [u8; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bytes[N - 1 - i] as Field) * v;\n            v = v * 256;\n        }\n        result\n    }\n}\n\n#[builtin(apply_range_constraint)]\nfn __assert_max_bit_size(value: Field, bit_size: u32) {}\n\n// `_radix` must be less than 256\n#[builtin(to_le_radix)]\nfn __to_le_radix<let N: u32>(value: Field, radix: u32) -> [u8; N] {}\n\n// `_radix` must be less than 256\n#[builtin(to_be_radix)]\nfn __to_be_radix<let N: u32>(value: Field, radix: u32) -> [u8; N] {}\n\n/// Decomposes `self` into its little endian bit decomposition as a `[u1; N]` array.\n/// This slice will be zero padded should not all bits be necessary to represent `self`.\n///\n/// # Failures\n/// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n/// be able to represent the original `Field`.\n///\n/// # Safety\n/// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n/// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n/// wrap around due to overflow when verifying the decomposition.\n#[builtin(to_le_bits)]\nfn __to_le_bits<let N: u32>(value: Field) -> [u1; N] {}\n\n/// Decomposes `self` into its big endian bit decomposition as a `[u1; N]` array.\n/// This array will be zero padded should not all bits be necessary to represent `self`.\n///\n/// # Failures\n/// Causes a constraint failure for `Field` values exceeding `2^N` as the resulting slice will not\n/// be able to represent the original `Field`.\n///\n/// # Safety\n/// Values of `N` equal to or greater than the number of bits necessary to represent the `Field` modulus\n/// (e.g. 254 for the BN254 field) allow for multiple bit decompositions. This is due to how the `Field` will\n/// wrap around due to overflow when verifying the decomposition.\n#[builtin(to_be_bits)]\nfn __to_be_bits<let N: u32>(value: Field) -> [u1; N] {}\n\n#[builtin(modulus_num_bits)]\npub comptime fn modulus_num_bits() -> u64 {}\n\n#[builtin(modulus_be_bits)]\npub comptime fn modulus_be_bits() -> [u1] {}\n\n#[builtin(modulus_le_bits)]\npub comptime fn modulus_le_bits() -> [u1] {}\n\n#[builtin(modulus_be_bytes)]\npub comptime fn modulus_be_bytes() -> [u8] {}\n\n#[builtin(modulus_le_bytes)]\npub comptime fn modulus_le_bytes() -> [u8] {}\n\n/// An unconstrained only built in to efficiently compare fields.\n#[builtin(field_less_than)]\nunconstrained fn __field_less_than(x: Field, y: Field) -> bool {}\n\npub(crate) unconstrained fn field_less_than(x: Field, y: Field) -> bool {\n    __field_less_than(x, y)\n}\n\n// Convert a 32 byte array to a field element by modding\npub fn bytes32_to_field(bytes32: [u8; 32]) -> Field {\n    // Convert it to a field element\n    let mut v = 1;\n    let mut high = 0 as Field;\n    let mut low = 0 as Field;\n\n    for i in 0..16 {\n        high = high + (bytes32[15 - i] as Field) * v;\n        low = low + (bytes32[16 + 15 - i] as Field) * v;\n        v = v * 256;\n    }\n    // Abuse that a % p + b % p = (a + b) % p and that low < p\n    low + high * v\n}\n\nfn lt_fallback(x: Field, y: Field) -> bool {\n    if is_unconstrained() {\n        // Safety: unconstrained context\n        unsafe {\n            field_less_than(x, y)\n        }\n    } else {\n        let x_bytes: [u8; 32] = x.to_le_bytes();\n        let y_bytes: [u8; 32] = y.to_le_bytes();\n        let mut x_is_lt = false;\n        let mut done = false;\n        for i in 0..32 {\n            if (!done) {\n                let x_byte = x_bytes[32 - 1 - i] as u8;\n                let y_byte = y_bytes[32 - 1 - i] as u8;\n                let bytes_match = x_byte == y_byte;\n                if !bytes_match {\n                    x_is_lt = x_byte < y_byte;\n                    done = true;\n                }\n            }\n        }\n        x_is_lt\n    }\n}\n\nmod tests {\n    use crate::{panic::panic, runtime, static_assert};\n    use super::{\n        field_less_than, modulus_be_bits, modulus_be_bytes, modulus_le_bits, modulus_le_bytes,\n    };\n\n    #[test]\n    // docs:start:to_be_bits_example\n    fn test_to_be_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_be_bits();\n        assert_eq(bits, [0, 0, 0, 0, 0, 0, 1, 0]);\n    }\n    // docs:end:to_be_bits_example\n\n    #[test]\n    // docs:start:to_le_bits_example\n    fn test_to_le_bits() {\n        let field = 2;\n        let bits: [u1; 8] = field.to_le_bits();\n        assert_eq(bits, [0, 1, 0, 0, 0, 0, 0, 0]);\n    }\n    // docs:end:to_le_bits_example\n\n    #[test]\n    // docs:start:to_be_bytes_example\n    fn test_to_be_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_be_bytes();\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 0, 2]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_bytes_example\n\n    #[test]\n    // docs:start:to_le_bytes_example\n    fn test_to_le_bytes() {\n        let field = 2;\n        let bytes: [u8; 8] = field.to_le_bytes();\n        assert_eq(bytes, [2, 0, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_bytes_example\n\n    #[test]\n    // docs:start:to_be_radix_example\n    fn test_to_be_radix() {\n        // 259, in base 256, big endian, is [1, 3].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_be_radix(256);\n        assert_eq(bytes, [0, 0, 0, 0, 0, 0, 1, 3]);\n        assert_eq(Field::from_be_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_be_radix_example\n\n    #[test]\n    // docs:start:to_le_radix_example\n    fn test_to_le_radix() {\n        // 259, in base 256, little endian, is [3, 1].\n        // i.e. 3 * 256^0 + 1 * 256^1\n        let field = 259;\n\n        // The radix (in this example, 256) must be a power of 2.\n        // The length of the returned byte array can be specified to be\n        // >= the amount of space needed.\n        let bytes: [u8; 8] = field.to_le_radix(256);\n        assert_eq(bytes, [3, 1, 0, 0, 0, 0, 0, 0]);\n        assert_eq(Field::from_le_bytes::<8>(bytes), field);\n    }\n    // docs:end:to_le_radix_example\n\n    #[test(should_fail_with = \"radix must be greater than 1\")]\n    fn test_to_le_radix_1() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(1);\n        } else {\n            panic(f\"radix must be greater than 1\");\n        }\n    }\n\n    // Updated test to account for Brillig restriction that radix must be greater than 2\n    #[test(should_fail_with = \"radix must be greater than 1\")]\n    fn test_to_le_radix_brillig_1() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 1;\n            let _: [u8; 8] = field.to_le_radix(1);\n        } else {\n            panic(f\"radix must be greater than 1\");\n        }\n    }\n\n    #[test(should_fail_with = \"radix must be a power of 2\")]\n    fn test_to_le_radix_3() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(3);\n        } else {\n            panic(f\"radix must be a power of 2\");\n        }\n    }\n\n    #[test]\n    fn test_to_le_radix_brillig_3() {\n        // this test should only fail in constrained mode\n        if runtime::is_unconstrained() {\n            let field = 1;\n            let out: [u8; 8] = field.to_le_radix(3);\n            let mut expected = [0; 8];\n            expected[0] = 1;\n            assert(out == expected, \"unexpected result\");\n        }\n    }\n\n    #[test(should_fail_with = \"radix must be less than or equal to 256\")]\n    fn test_to_le_radix_512() {\n        // this test should only fail in constrained mode\n        if !runtime::is_unconstrained() {\n            let field = 2;\n            let _: [u8; 8] = field.to_le_radix(512);\n        } else {\n            panic(f\"radix must be less than or equal to 256\")\n        }\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 16 limbs\")]\n    unconstrained fn not_enough_limbs_brillig() {\n        let _: [u8; 16] = 0x100000000000000000000000000000000.to_le_bytes();\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 16 limbs\")]\n    fn not_enough_limbs() {\n        let _: [u8; 16] = 0x100000000000000000000000000000000.to_le_bytes();\n    }\n\n    #[test]\n    unconstrained fn test_field_less_than() {\n        assert(field_less_than(0, 1));\n        assert(field_less_than(0, 0x100));\n        assert(field_less_than(0x100, 0 - 1));\n        assert(!field_less_than(0 - 1, 0));\n    }\n\n    #[test]\n    unconstrained fn test_large_field_values_unconstrained() {\n        let large_field = 0xffffffffffffffff;\n\n        let bits: [u1; 64] = large_field.to_le_bits();\n        assert_eq(bits[0], 1);\n\n        let bytes: [u8; 8] = large_field.to_le_bytes();\n        assert_eq(Field::from_le_bytes::<8>(bytes), large_field);\n\n        let radix_bytes: [u8; 8] = large_field.to_le_radix(256);\n        assert_eq(Field::from_le_bytes::<8>(radix_bytes), large_field);\n    }\n\n    #[test]\n    fn test_large_field_values() {\n        let large_val = 0xffffffffffffffff;\n\n        let bits: [u1; 64] = large_val.to_le_bits();\n        assert_eq(bits[0], 1);\n\n        let bytes: [u8; 8] = large_val.to_le_bytes();\n        assert_eq(Field::from_le_bytes::<8>(bytes), large_val);\n\n        let radix_bytes: [u8; 8] = large_val.to_le_radix(256);\n        assert_eq(Field::from_le_bytes::<8>(radix_bytes), large_val);\n    }\n\n    #[test]\n    fn test_decomposition_edge_cases() {\n        let zero_bits: [u1; 8] = 0.to_le_bits();\n        assert_eq(zero_bits, [0; 8]);\n\n        let zero_bytes: [u8; 8] = 0.to_le_bytes();\n        assert_eq(zero_bytes, [0; 8]);\n\n        let one_bits: [u1; 8] = 1.to_le_bits();\n        let expected: [u1; 8] = [1, 0, 0, 0, 0, 0, 0, 0];\n        assert_eq(one_bits, expected);\n\n        let pow2_bits: [u1; 8] = 4.to_le_bits();\n        let expected: [u1; 8] = [0, 0, 1, 0, 0, 0, 0, 0];\n        assert_eq(pow2_bits, expected);\n    }\n\n    #[test]\n    fn test_pow_32() {\n        assert_eq(2.pow_32(3), 8);\n        assert_eq(3.pow_32(2), 9);\n        assert_eq(5.pow_32(0), 1);\n        assert_eq(7.pow_32(1), 7);\n\n        assert_eq(2.pow_32(10), 1024);\n\n        assert_eq(0.pow_32(5), 0);\n        assert_eq(0.pow_32(0), 1);\n\n        assert_eq(1.pow_32(100), 1);\n    }\n\n    #[test]\n    fn test_sgn0() {\n        assert_eq(0.sgn0(), 0);\n        assert_eq(2.sgn0(), 0);\n        assert_eq(4.sgn0(), 0);\n        assert_eq(100.sgn0(), 0);\n\n        assert_eq(1.sgn0(), 1);\n        assert_eq(3.sgn0(), 1);\n        assert_eq(5.sgn0(), 1);\n        assert_eq(101.sgn0(), 1);\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 8 limbs\")]\n    fn test_bit_decomposition_overflow() {\n        // 8 bits can't represent large field values\n        let large_val = 0x1000000000000000;\n        let _: [u1; 8] = large_val.to_le_bits();\n    }\n\n    #[test(should_fail_with = \"Field failed to decompose into specified 4 limbs\")]\n    fn test_byte_decomposition_overflow() {\n        // 4 bytes can't represent large field values\n        let large_val = 0x1000000000000000;\n        let _: [u8; 4] = large_val.to_le_bytes();\n    }\n\n    #[test]\n    fn test_to_from_be_bytes_bn254_edge_cases() {\n        if crate::compat::is_bn254() {\n            // checking that decrementing this byte produces the expected 32 BE bytes for (modulus - 1)\n            let mut p_minus_1_bytes: [u8; 32] = modulus_be_bytes().as_array();\n            assert(p_minus_1_bytes[32 - 1] > 0);\n            p_minus_1_bytes[32 - 1] -= 1;\n\n            let p_minus_1 = Field::from_be_bytes::<32>(p_minus_1_bytes);\n            assert_eq(p_minus_1 + 1, 0);\n\n            // checking that converting (modulus - 1) from and then to 32 BE bytes produces the same bytes\n            let p_minus_1_converted_bytes: [u8; 32] = p_minus_1.to_be_bytes();\n            assert_eq(p_minus_1_converted_bytes, p_minus_1_bytes);\n\n            // checking that incrementing this byte produces 32 BE bytes for (modulus + 1)\n            let mut p_plus_1_bytes: [u8; 32] = modulus_be_bytes().as_array();\n            assert(p_plus_1_bytes[32 - 1] < 255);\n            p_plus_1_bytes[32 - 1] += 1;\n\n            let p_plus_1 = Field::from_be_bytes::<32>(p_plus_1_bytes);\n            assert_eq(p_plus_1, 1);\n\n            // checking that converting p_plus_1 to 32 BE bytes produces the same\n            // byte set to 1 as p_plus_1_bytes and otherwise zeroes\n            let mut p_plus_1_converted_bytes: [u8; 32] = p_plus_1.to_be_bytes();\n            assert_eq(p_plus_1_converted_bytes[32 - 1], 1);\n            p_plus_1_converted_bytes[32 - 1] = 0;\n            assert_eq(p_plus_1_converted_bytes, [0; 32]);\n\n            // checking that Field::from_be_bytes::<32> on the Field modulus produces 0\n            assert_eq(modulus_be_bytes().len(), 32);\n            let p = Field::from_be_bytes::<32>(modulus_be_bytes().as_array());\n            assert_eq(p, 0);\n\n            // checking that converting 0 to 32 BE bytes produces 32 zeroes\n            let p_bytes: [u8; 32] = 0.to_be_bytes();\n            assert_eq(p_bytes, [0; 32]);\n        }\n    }\n\n    #[test]\n    fn test_to_from_le_bytes_bn254_edge_cases() {\n        if crate::compat::is_bn254() {\n            // checking that decrementing this byte produces the expected 32 LE bytes for (modulus - 1)\n            let mut p_minus_1_bytes: [u8; 32] = modulus_le_bytes().as_array();\n            assert(p_minus_1_bytes[0] > 0);\n            p_minus_1_bytes[0] -= 1;\n\n            let p_minus_1 = Field::from_le_bytes::<32>(p_minus_1_bytes);\n            assert_eq(p_minus_1 + 1, 0);\n\n            // checking that converting (modulus - 1) from and then to 32 BE bytes produces the same bytes\n            let p_minus_1_converted_bytes: [u8; 32] = p_minus_1.to_le_bytes();\n            assert_eq(p_minus_1_converted_bytes, p_minus_1_bytes);\n\n            // checking that incrementing this byte produces 32 LE bytes for (modulus + 1)\n            let mut p_plus_1_bytes: [u8; 32] = modulus_le_bytes().as_array();\n            assert(p_plus_1_bytes[0] < 255);\n            p_plus_1_bytes[0] += 1;\n\n            let p_plus_1 = Field::from_le_bytes::<32>(p_plus_1_bytes);\n            assert_eq(p_plus_1, 1);\n\n            // checking that converting p_plus_1 to 32 LE bytes produces the same\n            // byte set to 1 as p_plus_1_bytes and otherwise zeroes\n            let mut p_plus_1_converted_bytes: [u8; 32] = p_plus_1.to_le_bytes();\n            assert_eq(p_plus_1_converted_bytes[0], 1);\n            p_plus_1_converted_bytes[0] = 0;\n            assert_eq(p_plus_1_converted_bytes, [0; 32]);\n\n            // checking that Field::from_le_bytes::<32> on the Field modulus produces 0\n            assert_eq(modulus_le_bytes().len(), 32);\n            let p = Field::from_le_bytes::<32>(modulus_le_bytes().as_array());\n            assert_eq(p, 0);\n\n            // checking that converting 0 to 32 LE bytes produces 32 zeroes\n            let p_bytes: [u8; 32] = 0.to_le_bytes();\n            assert_eq(p_bytes, [0; 32]);\n        }\n    }\n\n    /// Convert a little endian bit array to a field element.\n    /// If the provided bit array overflows the field modulus then the Field will silently wrap around.\n    fn from_le_bits<let N: u32>(bits: [u1; N]) -> Field {\n        static_assert(\n            N <= modulus_le_bits().len(),\n            \"N must be less than or equal to modulus_le_bits().len()\",\n        );\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bits[i] as Field) * v;\n            v = v * 2;\n        }\n        result\n    }\n\n    /// Convert a big endian bit array to a field element.\n    /// If the provided bit array overflows the field modulus then the Field will silently wrap around.\n    fn from_be_bits<let N: u32>(bits: [u1; N]) -> Field {\n        let mut v = 1;\n        let mut result = 0;\n\n        for i in 0..N {\n            result += (bits[N - 1 - i] as Field) * v;\n            v = v * 2;\n        }\n        result\n    }\n\n    #[test]\n    fn test_to_from_be_bits_bn254_edge_cases() {\n        if crate::compat::is_bn254() {\n            // checking that decrementing this bit produces the expected 254 BE bits for (modulus - 1)\n            let mut p_minus_1_bits: [u1; 254] = modulus_be_bits().as_array();\n            assert(p_minus_1_bits[254 - 1] > 0);\n            p_minus_1_bits[254 - 1] -= 1;\n\n            let p_minus_1 = from_be_bits::<254>(p_minus_1_bits);\n            assert_eq(p_minus_1 + 1, 0);\n\n            // checking that converting (modulus - 1) from and then to 254 BE bits produces the same bits\n            let p_minus_1_converted_bits: [u1; 254] = p_minus_1.to_be_bits();\n            assert_eq(p_minus_1_converted_bits, p_minus_1_bits);\n\n            // checking that incrementing this bit produces 254 BE bits for (modulus + 4)\n            let mut p_plus_4_bits: [u1; 254] = modulus_be_bits().as_array();\n            assert(p_plus_4_bits[254 - 3] < 1);\n            p_plus_4_bits[254 - 3] += 1;\n\n            let p_plus_4 = from_be_bits::<254>(p_plus_4_bits);\n            assert_eq(p_plus_4, 4);\n\n            // checking that converting p_plus_4 to 254 BE bits produces the same\n            // bit set to 1 as p_plus_4_bits and otherwise zeroes\n            let mut p_plus_4_converted_bits: [u1; 254] = p_plus_4.to_be_bits();\n            assert_eq(p_plus_4_converted_bits[254 - 3], 1);\n            p_plus_4_converted_bits[254 - 3] = 0;\n            assert_eq(p_plus_4_converted_bits, [0; 254]);\n\n            // checking that Field::from_be_bits::<254> on the Field modulus produces 0\n            assert_eq(modulus_be_bits().len(), 254);\n            let p = from_be_bits::<254>(modulus_be_bits().as_array());\n            assert_eq(p, 0);\n\n            // checking that converting 0 to 254 BE bytes produces 254 zeroes\n            let p_bits: [u1; 254] = 0.to_be_bits();\n            assert_eq(p_bits, [0; 254]);\n        }\n    }\n\n    #[test]\n    fn test_to_from_le_bits_bn254_edge_cases() {\n        if crate::compat::is_bn254() {\n            // checking that decrementing this bit produces the expected 254 LE bits for (modulus - 1)\n            let mut p_minus_1_bits: [u1; 254] = modulus_le_bits().as_array();\n            assert(p_minus_1_bits[0] > 0);\n            p_minus_1_bits[0] -= 1;\n\n            let p_minus_1 = from_le_bits::<254>(p_minus_1_bits);\n            assert_eq(p_minus_1 + 1, 0);\n\n            // checking that converting (modulus - 1) from and then to 254 BE bits produces the same bits\n            let p_minus_1_converted_bits: [u1; 254] = p_minus_1.to_le_bits();\n            assert_eq(p_minus_1_converted_bits, p_minus_1_bits);\n\n            // checking that incrementing this bit produces 254 LE bits for (modulus + 4)\n            let mut p_plus_4_bits: [u1; 254] = modulus_le_bits().as_array();\n            assert(p_plus_4_bits[2] < 1);\n            p_plus_4_bits[2] += 1;\n\n            let p_plus_4 = from_le_bits::<254>(p_plus_4_bits);\n            assert_eq(p_plus_4, 4);\n\n            // checking that converting p_plus_4 to 254 LE bits produces the same\n            // bit set to 1 as p_plus_4_bits and otherwise zeroes\n            let mut p_plus_4_converted_bits: [u1; 254] = p_plus_4.to_le_bits();\n            assert_eq(p_plus_4_converted_bits[2], 1);\n            p_plus_4_converted_bits[2] = 0;\n            assert_eq(p_plus_4_converted_bits, [0; 254]);\n\n            // checking that Field::from_le_bits::<254> on the Field modulus produces 0\n            assert_eq(modulus_le_bits().len(), 254);\n            let p = from_le_bits::<254>(modulus_le_bits().as_array());\n            assert_eq(p, 0);\n\n            // checking that converting 0 to 254 LE bytes produces 254 zeroes\n            let p_bits: [u1; 254] = 0.to_le_bits();\n            assert_eq(p_bits, [0; 254]);\n        }\n    }\n}\n","path":"std/field/mod.nr"},"50":{"source":"use elgamal::{add_ciphertexts, CipherText, encrypt, decrypt, public_key, verify_embedding};\nuse std::embedded_curve_ops::EmbeddedCurvePoint;\n\n// Helper: Negate a point\nfn negate_point(p: EmbeddedCurvePoint) -> EmbeddedCurvePoint {\n    EmbeddedCurvePoint { x: p.x, y: -p.y, is_infinite: p.is_infinite }\n}\n\n// Helper: Subtract ciphertexts (homomorphic)\nfn subtract_ciphertexts(a: CipherText, b: CipherText) -> CipherText {\n    let neg_b = (negate_point(b.0), negate_point(b.1));\n    add_ciphertexts(a, neg_b)\n}\n\n// ==================== MAIN CIRCUIT ====================\n// Simple Wallet: Deposit (receive) and Withdraw (send)\n// methodTag: 2=deposit, 3=withdraw\n\nfn main(\n    // Private\n    current_balance: Field,\n    operation_amount: Field,  // deposit/withdraw amount\n    r_old_balance: Field,\n    r_new_balance: Field,\n\n    // Public\n    sender_pubkey: pub EmbeddedCurvePoint,\n    old_balance_x1: pub EmbeddedCurvePoint,\n    old_balance_x2: pub EmbeddedCurvePoint,\n    from: pub Field,\n    to: pub Field,\n    token: pub Field,\n    chainId: pub Field,\n    methodTag: pub Field,  // 2=deposit, 3=withdraw\n) -> pub (\n    (EmbeddedCurvePoint, EmbeddedCurvePoint),  // new_balance_ct\n    Field  // revealed_amount (for deposit/withdraw)\n) {\n    // Range constraints\n    current_balance.assert_max_bit_size::<40>();\n    operation_amount.assert_max_bit_size::<40>();\n\n    // Verify old balance encryption\n    let old_balance_ct = (old_balance_x1, old_balance_x2);\n    let computed_old_balance = encrypt(sender_pubkey, current_balance, r_old_balance);\n    assert(computed_old_balance == old_balance_ct);\n\n    let mut new_balance = current_balance;\n    let mut revealed_amount = 0;\n\n    // DEPOSIT (methodTag == 2) - Receive money\n    if methodTag == 2 {\n        // Add to balance\n        new_balance = current_balance + operation_amount;\n        new_balance.assert_max_bit_size::<40>();\n        revealed_amount = operation_amount;  // Reveal amount for contract\n    }\n\n    // WITHDRAW (methodTag == 3) - Send money (to any address)\n    if methodTag == 3 {\n        // Subtract from balance (underflow check via subtraction)\n        new_balance = current_balance - operation_amount;\n        new_balance.assert_max_bit_size::<40>();\n        revealed_amount = operation_amount;  // Reveal amount for contract\n    }\n\n    // Encrypt new balance\n    let new_balance_ct = encrypt(sender_pubkey, new_balance, r_new_balance);\n\n    (\n        (new_balance_ct.0, new_balance_ct.1),\n        revealed_amount\n    )\n}\n\n// ==================== TESTS ====================\n\n#[test]\nfn test_deposit() {\n    let priv_key = 42;\n    let pub_key = public_key(priv_key);\n\n    let old_balance_ct = encrypt(pub_key, 500, 111);\n\n    let (new_ct, amt) = main(\n        500, 300, 111, 222,\n        pub_key, old_balance_ct.0, old_balance_ct.1,\n        1, 2, 3, 4, 2  // methodTag=2 (deposit)\n    );\n\n    let new_balance = decrypt((new_ct.0, new_ct.1), priv_key);\n    verify_embedding(new_balance, 800);\n    assert(amt == 300);  // Deposit amount revealed\n}\n\n#[test]\nfn test_withdraw() {\n    let priv_key = 42;\n    let pub_key = public_key(priv_key);\n\n    let old_balance_ct = encrypt(pub_key, 1000, 111);\n\n    let (new_ct, amt) = main(\n        1000, 250, 111, 222,\n        pub_key, old_balance_ct.0, old_balance_ct.1,\n        1, 2, 3, 4, 3  // methodTag=3 (withdraw)\n    );\n\n    let new_balance = decrypt((new_ct.0, new_ct.1), priv_key);\n    verify_embedding(new_balance, 750);\n    assert(amt == 250);  // Amount revealed for withdraw\n}\n\n#[test(should_fail)]\nfn test_insufficient_balance_fails() {\n    let sender_pub = public_key(42);\n    let old_balance_ct = encrypt(sender_pub, 100, 111);\n\n    let _ = main(\n        100, 200, 111, 222,\n        sender_pub, old_balance_ct.0, old_balance_ct.1,\n        1, 2, 3, 4, 3  // Withdraw more than balance - should fail\n    );\n}\n","path":"/root/arg25-Projects/zk-wallet/wallet_proof/src/main.nr"},"51":{"source":"// ElGamal Cryptosystem Implementation\n//\n// This library implements the elliptic curve variant of the ElGamal cryptosystem as described\n// in the accompanying documentation. It provides functions for key generation, message embedding,\n// encryption and decryption with the following features:\n//\n// - Curve-agnostic implementation: No elliptic curve parameters are hardcoded in this library\n// - Works with any curve supported by the underlying proving system\n// - Preserves the additive homomorphic property described in Section 2.4\n// - Implements the message embedding approach from Section 2.5\n//\n// The implementation follows the mathematical formulation in the documentation with\n// function signatures designed to be simple and composable.\n\npub mod tests;\n\nuse std::embedded_curve_ops::{\n    embedded_curve_add, EmbeddedCurvePoint, EmbeddedCurveScalar, fixed_base_scalar_mul,\n    multi_scalar_mul,\n};\n\n// #region utils\n\npub type CipherText = (EmbeddedCurvePoint, EmbeddedCurvePoint);\n\n/// Field to point, x . G\npub fn field_to_point(x: Field) -> EmbeddedCurvePoint {\n    fixed_base_scalar_mul(EmbeddedCurveScalar::from_field(x))\n}\n\n// #endregion utils\n\n/// Implements key generation as in Section 2.1\n/// Computes H = x . G (Equation 2.1)\npub fn public_key(priv_key: Field) -> EmbeddedCurvePoint {\n    field_to_point(priv_key)\n}\n\n/// Encryption as defined in Section 2.2\n/// Computes (C_1, C_2) = (r . G, r . H + P_m)`$ (Equation 2.2)\npub fn encrypt(pub_key: EmbeddedCurvePoint, message: Field, randomness: Field) -> CipherText {\n    // @Optimise: Use multi_scalar_mul instead of separate fixed_base_scalar_mul\n    encrypt_pt(pub_key, field_to_point(message), randomness)\n}\n\n/// Encryption as defined in Section 2.2\n/// Computes (C_1, C_2) = (r . G, r . H + P_m)`$ (Equation 2.2)\npub fn encrypt_pt(\n    pub_key: EmbeddedCurvePoint,\n    embedded_message: EmbeddedCurvePoint,\n    randomness: Field,\n) -> CipherText {\n    // @Optimise: Use multi_scalar_mul instead of separate fixed_base_scalar_mul\n    let c1 = field_to_point(randomness);\n    let c2 = embedded_curve_add(\n        embedded_message,\n        multi_scalar_mul([pub_key], [EmbeddedCurveScalar::from_field(randomness)]),\n    );\n    (c1, c2)\n}\n\n/// Decryption as per Section 2.3\n/// Computes C_2 - x . C_1 = P_m\npub fn decrypt(ct: CipherText, priv_key: Field) -> EmbeddedCurvePoint {\n    let x = EmbeddedCurveScalar::from_field(priv_key);\n    let diff = multi_scalar_mul([ct.0], [x]);\n    embedded_curve_add(ct.1, -diff)\n}\n\n/// Additively homomorphic property as in Section 2.4\n/// Computes (A_1 + B_1, A_2 + B_2)\npub fn add_ciphertexts(a: CipherText, b: CipherText) -> CipherText {\n    (embedded_curve_add(a.0, b.0), embedded_curve_add(a.1, b.1))\n}\n\n/// Message embedding function f(m) = m . G from Section 2.5\n/// Fails if message is over 40 bits\npub fn embed_message(m: Field) -> EmbeddedCurvePoint {\n    m.assert_max_bit_size::<40>();\n    field_to_point(m)\n}\n\n/// Verifies that a point is the correct embedding of a message\n/// Implements the verification function from Section 2.5\npub fn verify_embedding(embedding: EmbeddedCurvePoint, m: Field) {\n    assert(embedding == field_to_point(m));\n}\n","path":"/root/arg25-Projects/zk-wallet/noir-v1-elgamal/noir/lib/src/lib.nr"}},"expression_width":{"Bounded":{"width":4}}}